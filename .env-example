# Model source: "openai" for GPT models, "local" for Ollama
MODEL_SOURCE=local  # default to OpenAI

# Your OpenAI API key for accessing OpenAI services
OPENAI_API_KEY=your-openai-api-key

# The LLM model
LLM_MODEL=llama3.2:latest

# The LLM max number of tokens
LLM_MAX_TOKENS=128000

# The embedding model
EMBEDDING_MODEL=nomic-embed-text:latest

# The dimension of the embeddings used by OpenAI
EMBEDDING_DIM=768

# Max chunk size for embeddings
CHUNK_SIZE_MAX=512

# Max chunk overlap percentage
CHUNK_OVERLAP_PERCENTAGE=25

# The Tokenizer encoding used calculating the number of tokens
TOKEN_ENCODING=cl100k_base

# Path to the folder containing documents to be ingested
INGEST_PATH=../ingest

# The system prompt used by the chatbot to generate responses
SYSTEM_PROMPT=Please provide responses based only on the context document chunks provided if they are relevant to the users prompt. If the context document chunks are not relevant, or if the information is not available, please let me know. Do not provide information beyond what is available in the context documents. Chunks are sorted by relevancy, where the first chunk listed is the most relevant. Note: Chunks may overlap and so may contain duplicate information.

# Threshold for document similarity; documents with a similarity score below this value will be ignored
SIMILARITY_THRESHOLD=0.25

# The number of top similar results to be considered for generating responses
TOP_SIMILARITY_RESULTS=3

# Text-to-speech voice to use
TTS_VOICE=Alex_0